
# Description: config file for default parameters of scenenet_ts40k experiment
# Author: Diogo Mateus

project:
  value: 'SceneNet1.5'
output_dir: 
  value: 'experiments/scenenet_ts40k/outputs'
# ------------------ #
# dataset config
# ------------------ #
dataset:
  value: 'ts40k'
preprocessed:
  value: True
  description: 'If True, uses the preprocessed the dataset'
load_into_memory:
  value: False
data_path:
  value: ''
num_classes:
  value: 6
# num_data_channels:
#   value: 0
  # description: 'Number of channels in the dataset'
voxel_grid_size:
  value: (64, 64, 64)
voxel_size:
  value: None
batch_size:
  value: 1
ignore_index:
  value: 0 # noise
num_workers: 
  value: 0
val_split:
  value: 0.1
test_split:
  value: 0.3
fps_points:
  value: 10000
min_points:
  value: null
  description: 'Number of points to sample from the point cloud with farthest point sampling'
# ------------------ #
# model config
# ------------------ #
model:
  value: 'scenenet'
cylinder_geneo:
  value: 16
arrow_geneo:
  value: 16
neg_sphere_geneo:
  value: 16
disk_geneo:
  value: 16
cone_geneo:
  value: 16
ellipsoid_geneo:
  value: 16
num_observers:
  value: "[8]"
kernel_size:
  value: (12, 6, 6)
hidden_dims:
  value: '[512, 256, 128, 64, 64, 32]'
# ------------------ #
# training config
# ------------------ #
optimizer:
  value: 'adam' #'adam' 
learning_rate:
  value: 0.001
max_epochs:
  value: 80 # -1 for infinite
accelerator:
  value: 'gpu' # 'ddp' or 'dp'
devices:
  value: -1 # -1 for all available gpus
num_nodes:
  value: 1
strategy:
  value: 'auto' # 'ddp'
early_stop_metric:
  value: 'val_MulticlassJaccardIndex'
# ------------------ #
#criterion config
# ------------------ #
criterion:
  value: 'cross_entropy'
geneo_criterion:
  value: True
  description: 'If True, uses the geneo wrapper criterion, otherwise uses the standard criterion'
class_weights:
  value: True
  description: 'Use class weights in the loss function'
convex_weight:
  value: 0.0001
# tversky_alpha:
#   value: 1
# tversky_beta:
#   value: 1
# tversky_smooth:
#   value: 1.0e-6
# focal_gamma:
#   value: 1
# ------------------ #
# Lit Trainer config
# ------------------ #
fast_dev_run:
  value: True
precision: # 16 or 32 FPU precision
  value: 32
  description: 'FPU precision'
auto_lr_find:
  value: False
auto_scale_batch_size:
  value: False
profiler:
  value: False
  description: 'PyTorch Lightning profiler'
accumulate_grad_batches:
  value: 1
  description: 'Accumulate gradients on k batches before performing a backward pass'
save_onnx:
  value: False
  description: 'Save model in onnx format'
# ------------------ #
# Checkpoint config
# ------------------ #
resume_from_checkpoint:
  value: False
checkpoint_dir:
  value:  '${experiment_path}/wandb/run-20240528_184251-pzk1mkbv/files/checkpoints/' # cnn
  # value: '${experiment_path}/best_model/checkpoints'
  # value: '${experiment_path}/wandb/best-run/files/checkpoints/'
resume_checkpoint_name:
  value: MulticlassJaccardIndex # 'FbetaScore', 'train_loss', last, 'best', 'F1Score'
checkpoint_every_n_epochs: # This parameter and the next one are mutually exclusive
  value: 1 # every n epochs
checkpoint_every_n_steps:
  value: 0 # every n steps
  
